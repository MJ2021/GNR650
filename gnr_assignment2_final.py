# -*- coding: utf-8 -*-
"""GNR_ASSIGNMENT2_FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FypX6Fi6Vnn3WKY0XagzVNeBspjD_QRp
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision.models import vision_transformer
from torch.utils.data import DataLoader
import ssl

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ssl._create_default_https_context = ssl._create_unverified_context
transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])
dataset = torchvision.datasets.EuroSAT(root="", download = True, transform = transform)

ratio = 0.85                                                                                    # Train test split
train_samp = int(ratio * len(dataset))
test_samp = len(dataset) - train_samp
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_samp, test_samp])

"""**Making the dataloaders for the train and test dataset**"""

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)
test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)

"""## 1. Fine tuning the final layer

Making all the layers except the final layer as non trainable
"""

model = vision_transformer.vit_b_32(pretrained=True)
model.heads.head = nn.Linear(in_features=768,out_features=10,bias=True)

for param in model.parameters():
    param.requires_grad = False
for param in model.heads.head.parameters():
    param.requires_grad = True

model = model

for name, param in model.named_parameters():
  print(name, param.requires_grad)

"""**We can observe that only the final layer in the above model is trainable**"""

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 1e-3)

model.to(device)

"""**Defining the activation function**"""

import matplotlib.pyplot as plt

activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

for epoch in range(2):
    # Training the model
    model.train()
    for images, labels in train_loader:  # Iterate through DataLoader
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f'Epochs [{epoch + 1}/{2}]')
    print(f'Training Loss: {loss.item():.4f}')

# Testing
model.eval()
actual = 0
total = 0

with torch.no_grad():
    for images, labels in test_loader:  # Iterate through your test DataLoader
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        actual += (predicted == labels).sum().item()

# Test accuracy
test_accuracy = 100 * actual / total
print(f'Testing Accuracy: {test_accuracy:.2f}%')

model.encoder.layers.encoder_layer_6.register_forward_hook(get_activation("1"))

for i, l in test_loader:
  img1 = i
  break

plt.imshow(img1[10].cpu().detach().numpy().transpose(1,2,0))
plt.show()

output = model(img1[0][None,:,:,:].to(device))

a = activation["1"][0,:,:][1:,:]
img = a[:, 3:6].reshape(7,7,3)
plt.figure(figsize=(3,3))
plt.imshow(img.cpu().detach().numpy())

"""**NOW WE WILL JUST RUN THE ABOVE CODE FOR ALL 3 OTHER CASES AFTER CHANGING THE TRAINABLE LAYERS**

## 2. Finetuning the bottom layers
"""

model = vision_transformer.vit_b_16(pretrained=True)
model.heads.head = nn.Linear(in_features=768,out_features=10,bias=True)

for param in model.parameters():
    param.requires_grad = True

for param in model.heads.head.parameters():
    param.requires_grad = False

model.to(device)

for name, param in model.named_parameters():
  print(name, param.requires_grad)

for epoch in range(2):
    # Training
    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f'Epochs [{epoch + 1}/{2}]')
    print(f'Training Loss: {loss.item():.4f}')

# Testing
model.eval()
actual = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        actual += (predicted == labels).sum().item()

# Test accuracy
test_accuracy = 100 * actual / total
print(f'Testing Accuracy: {test_accuracy:.2f}%')

activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

model.encoder.layers.encoder_layer_6.register_forward_hook(get_activation("2"))
for i, l in test_loader:
  img1 = i
  break

plt.imshow(img1[10].cpu().detach().numpy().transpose(1,2,0))
plt.show()

output = model(img1[0][None,:,:,:].to(device))

a = activation["2"][0,:,:][1:,:]
img = a[:, 3:6].reshape(14,14,3)
plt.figure(figsize=(3,3))
plt.imshow(img.cpu().detach().numpy())

"""## 3. Full fine tune on the eurosat data"""

model = vision_transformer.vit_b_16(pretrained=True)
model.heads.head = nn.Linear(in_features=768,out_features=10,bias=True)

for param in model.parameters():
    param.requires_grad = True

model.to(device)

for name, param in model.named_parameters():
  print(name, param.requires_grad)

for epoch in range(2):
    # Training
    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f'Epochs [{epoch + 1}/{2}]')
    print(f'Training Loss: {loss.item():.4f}')

# Testing
model.eval()
actual = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        actual += (predicted == labels).sum().item()

# Test accuracy
test_accuracy = 100 * actual / total
print(f'Testing Accuracy: {test_accuracy:.2f}%')

activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

model.encoder.layers.encoder_layer_6.register_forward_hook(get_activation("3"))
for i, l in test_loader:
  img1 = i
  break

plt.imshow(img1[10].cpu().detach().numpy().transpose(1,2,0))
plt.show()

output = model(img1[0][None,:,:,:].to(device))

a = activation["3"][0,:,:][1:,:]
img = a[:, 3:6].reshape(14,14,3)
plt.figure(figsize=(3,3))
plt.imshow(img.cpu().detach().numpy())

"""## 4. No fine tuning"""

model = vision_transformer.vit_b_16(pretrained=True)
model.heads.head = nn.Linear(in_features=768,out_features=10,bias=True)

for param in model.parameters():
    param.requires_grad = False
model.to(device)

for name, param in model.named_parameters():
  print(name, param.requires_grad)

# Testing
model.eval()
actual = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        actual += (predicted == labels).sum().item()

# Test accuracy
test_accuracy = 100 * actual / total
print(f'Testing Accuracy: {test_accuracy:.2f}%')

activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

model.encoder.layers.encoder_layer_6.register_forward_hook(get_activation("4"))
for i, l in test_loader:
  img1 = i
  break

plt.imshow(img1[10].cpu().detach().numpy().transpose(1,2,0))
plt.show()

output = model(img1[0][None,:,:,:].to(device))

a = activation["4"][0,:,:][1:,:]
img = a[:, 3:6].reshape(14,14,3)
plt.figure(figsize=(3,3))
plt.imshow(img.cpu().detach().numpy())